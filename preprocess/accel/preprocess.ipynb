{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import lared.accel.constants.constants as const\n",
    "from jose.accel.preproc import interpolate\n",
    "from lared_dataset.constants import (\n",
    "    raw_accel_path,\n",
    "    processed_accel_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = pathlib.Path(raw_accel_path)\n",
    "MAPPING_FILE    = base_path / \"mapping.csv\"\n",
    "MASTER_PICKLE_PATH = base_path / \"master_data.pkl\"\n",
    "VALID_AUDIO_SEGMENTS_PATH = \"../valid_audio_segments.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "balloon_pop_1_video_frame = 23030 # to \n",
    "balloon_pop_1_accel_frame = 45977 + 19/34\n",
    "\n",
    "balloon_pop_2_video_frame = 74844\n",
    "balloon_pop_2_accel_frame = 47706 + 23/28\n",
    "\n",
    "balloon_pop_3_video_frame = 166836.5\n",
    "balloon_pop_3_accel_frame = 50776 + 30.5/32\n",
    "\n",
    "frame_to_accel = interp1d([balloon_pop_1_video_frame, balloon_pop_3_video_frame], [balloon_pop_1_accel_frame, balloon_pop_3_accel_frame], fill_value=\"extrapolate\")\n",
    "video_seconds_to_accel_sample = interp1d([balloon_pop_1_video_frame/29.97, balloon_pop_3_video_frame/29.97], [balloon_pop_1_accel_frame, balloon_pop_3_accel_frame], fill_value=\"extrapolate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the array to map from PID to node ID\n",
    "mapping_arr = np.loadtxt(MAPPING_FILE, delimiter=',',dtype=int)\n",
    "keys = mapping_arr[:,1]\n",
    "vals = mapping_arr[:,0]\n",
    "mapping = dict(zip(keys,vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the accel stuff\n",
    "master_df = pd.read_pickle(str(MASTER_PICKLE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_seg = pickle.load(open(VALID_AUDIO_SEGMENTS_PATH,'rb'))\n",
    "valid_seg = [el[1] for el in valid_seg]\n",
    "pid_to_valid_seg = {el[0]: (video_seconds_to_accel_sample(el[1]/1000).item(), video_seconds_to_accel_sample(el[2]/1000).item()) for el in valid_seg}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting accel per subject\n",
    "Mapping from pid to accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(accel):\n",
    "    f = interp1d(accel[:, 0], accel[:, 1:], axis=0)\n",
    "\n",
    "    if not np.all( np.diff(accel[:,0].squeeze()) >= 0 ):\n",
    "        print('not in order')\n",
    "\n",
    "    x = np.arange(accel[0, 0], accel[-2, 0], 0.05)\n",
    "\n",
    "    try:\n",
    "        fx = f(x)\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    \n",
    "    return np.hstack([x[:,None], fx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 not in mapping\n",
      "failed accel for pid 21\n",
      "8 not in pid_to_valid_seg\n",
      "failed accel for pid 9\n",
      "16 not in mapping\n",
      "18 not in mapping\n",
      "23 not in mapping\n",
      "26 not in mapping\n",
      "29 not in mapping\n",
      "39 not in pid_to_valid_seg\n",
      "49 not in mapping\n",
      "failed accel for pid 1\n",
      "52 not in mapping\n",
      "54 not in mapping\n",
      "56 not in mapping\n",
      "57 not in mapping\n",
      "64 not in mapping\n",
      "38 not in pid_to_valid_seg\n",
      "73 not in mapping\n",
      "76 not in mapping\n",
      "78 not in mapping\n",
      "40 not in pid_to_valid_seg\n",
      "37 not in pid_to_valid_seg\n",
      "84 not in mapping\n",
      "91 not in mapping\n",
      "36 not in pid_to_valid_seg\n",
      "107 not in mapping\n"
     ]
    }
   ],
   "source": [
    "grouped_df = master_df.groupby('Node')\n",
    "subj_accel = dict()\n",
    "subj_accel_interp = {}\n",
    "for name, group in grouped_df:\n",
    "    \n",
    "    # Midge was not used in the data collection\n",
    "    if name not in mapping:\n",
    "        print('{:d} not in mapping'.format(name))\n",
    "        continue\n",
    "        \n",
    "    pid = mapping[name]\n",
    "    \n",
    "    # There was no valid data for this Midge\n",
    "    # Possibly because it was worn very shortly or\n",
    "    # not during mingling\n",
    "    if pid not in pid_to_valid_seg:\n",
    "        print('{:d} not in pid_to_valid_seg'.format(pid))\n",
    "        continue\n",
    "    subj_valid_seg = pid_to_valid_seg[pid]\n",
    "    \n",
    "    # Filter device that failed during data collection\n",
    "    if name in const.FAILED_ACCEL:\n",
    "        print('failed accel for pid {:d}'.format(pid))\n",
    "        continue\n",
    "    \n",
    "    # Chalcedony frames are 1s, with 20 samples each\n",
    "    def assert_len(x):\n",
    "        assert len(x) == 20\n",
    "        \n",
    "    frame_nums = group['Frame_No'].to_numpy()\n",
    "    diffs = np.diff(frame_nums)\n",
    "    first_idx = np.argmax(diffs) # find when the sync jump occurs\n",
    "        \n",
    "    group['x'].apply(assert_len)\n",
    "    group['y'].apply(assert_len)\n",
    "    group['z'].apply(assert_len)\n",
    "    \n",
    "    t = np.concatenate([np.arange(t, t+1, 0.05) for t in frame_nums])\n",
    "    x = np.concatenate(group['x'].tolist())\n",
    "    y = np.concatenate(group['y'].tolist())\n",
    "    z = np.concatenate(group['z'].tolist())\n",
    "        \n",
    "    accel = np.hstack([t[:,None],x[:,None],y[:,None],z[:,None]])[(first_idx+1)*20:,:]\n",
    "    accel = accel[(accel[:,0] > subj_valid_seg[0]) & (accel[:,0] < subj_valid_seg[1]), :] # filter out accel out of valid segment\n",
    "    \n",
    "    # Normalization per subject\n",
    "    accel[:,1:] = StandardScaler().fit_transform(accel[:,1:])\n",
    "    \n",
    "    # Interpolation to fill in any holes in the data.\n",
    "    # Should not change existing samples.\n",
    "    interp_accel = interpolate(accel)\n",
    "    \n",
    "    subj_accel[pid] = accel\n",
    "    subj_accel_interp[pid] = interp_accel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(subj_accel_interp, open(os.path.join(processed_accel_path, 'subj_accel_interp.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.52090000e+04, -1.24252884e-01, -2.28880847e+00,\n",
       "        -2.26937107e+00],\n",
       "       [ 4.52090500e+04, -1.42610644e-01, -2.28880847e+00,\n",
       "        -2.08869005e+00],\n",
       "       [ 4.52091000e+04, -1.42610644e-01, -2.00305177e+00,\n",
       "        -2.08869005e+00],\n",
       "       ...,\n",
       "       [ 5.08208500e+04, -6.12569281e-01,  5.68758467e-01,\n",
       "         6.32153493e-01],\n",
       "       [ 5.08209000e+04, -8.47548600e-01,  8.54515161e-01,\n",
       "         6.32153493e-01],\n",
       "       [ 5.08209500e+04, -8.47548600e-01,  5.68758467e-01,\n",
       "         4.50763923e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_accel[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.52090000e+04, -1.24252884e-01, -2.28880847e+00,\n",
       "        -2.26937107e+00],\n",
       "       [ 4.52090500e+04, -1.42610644e-01, -2.28880847e+00,\n",
       "        -2.08869005e+00],\n",
       "       [ 4.52091000e+04, -1.42610644e-01, -2.00305177e+00,\n",
       "        -2.08869005e+00],\n",
       "       ...,\n",
       "       [ 5.08208000e+04, -6.12569281e-01,  5.68758467e-01,\n",
       "         4.50765108e-01],\n",
       "       [ 5.08208500e+04, -6.12570816e-01,  5.68760334e-01,\n",
       "         6.32153493e-01],\n",
       "       [ 5.08209000e+04, -8.47548600e-01,  8.54513294e-01,\n",
       "         6.32152308e-01]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subj_accel_interp[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ff63645dd16f55240e07095d3c46f4fac3f89ef16802cfaceca713f6cf38dfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
